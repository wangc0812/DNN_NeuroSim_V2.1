=================FLAGS==================
type: cifar10
batch_size: 1024
epochs: 1
grad_scale: 8
seed: 117
log_interval: 100
test_interval: 1
logdir: /home/leon/DNN_NeuroSim_V2.1/Training_pytorch/log/default/ADCprecision=6/batch_size=1024/cellBit=4/decreasing_lr=200,250/detect=1/grad_scale=8/inference=1/onoffratio=10/seed=117/subArray=128/t=0/target=0.5/type=cifar10/v=0/vari=0/wl_activate=8/wl_error=8/wl_grad=8/wl_weight=8
decreasing_lr: 200,250
wl_weight: 8
wl_grad: 8
wl_activate: 8
wl_error: 8
inference: 1
onoffratio: 10
cellBit: 4
subArray: 128
ADCprecision: 6
vari: 0
t: 0
v: 0
detect: 1
target: 0.5
========================================
Sequential(
  (0): QConv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (1): ReLU()
  (2): QConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (3): ReLU()
  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (5): QConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (6): ReLU()
  (7): QConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (8): ReLU()
  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (10): QConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (11): ReLU()
  (12): QConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (13): ReLU()
  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
Sequential(
  (0): QLinear(in_features=8192, out_features=1024, bias=False)
  (1): ReLU(inplace=True)
  (2): QLinear(in_features=1024, out_features=10, bias=False)
)
